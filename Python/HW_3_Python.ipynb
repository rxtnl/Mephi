{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MXXTuy_o0sjk",
        "outputId": "7a7cafa4-85b9-4fb3-efb9-c4c4237cb246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.8/953.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U kaggle_environments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from kaggle_environments import make, evaluate"
      ],
      "metadata": {
        "id": "yz23vWHD0wcj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опишем стратегию агента, который всегда выбирает \"камень\". В терминах числового представления это соответствует значению 0."
      ],
      "metadata": {
        "id": "0kuo6IOxiRub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rock_agent.py\n",
        "\n",
        "#Example of the simple agent\n",
        "#0 - rock\n",
        "#1 - paper\n",
        "#2 - scissors\n",
        "def your_agent(observation, configuration):\n",
        "    return 0"
      ],
      "metadata": {
        "id": "bqTqV7B92rJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6861f2e4-29d5-4a28-d6f8-d8c0e27b09cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting rock_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте попробуем учитывать прошлые действия соперника. Опишем агента, который повторяет действие оппонента с предыдущего хода."
      ],
      "metadata": {
        "id": "et1J5hUGigeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile copy_opponent.py\n",
        "\n",
        "#Example\n",
        "def copy_opponent(observation, configuration):\n",
        "    #in case we have information about opponent last move\n",
        "    if observation.step > 0:\n",
        "        return observation.lastOpponentAction\n",
        "    #initial step\n",
        "    else:\n",
        "        return random.randrange(0, configuration.signs)"
      ],
      "metadata": {
        "id": "7l6Ttw6qi0jk",
        "outputId": "0621240d-530a-43fe-95b4-56eb78db6c2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting copy_opponent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используем функцию evaluate из библиотеки kaggle_environments, чтобы запустить наших агентов и провести эксперимент на заданном числе игр."
      ],
      "metadata": {
        "id": "ExgIpXUVjbjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"rock_agent.py\", \"copy_opponent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "id": "wv6Ip6M004xa",
        "outputId": "fb574a2d-130d-4c48-ab52-9944d6952a09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, None]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"rock_agent.py\", \"paper\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "id": "FC6_QWe9k3rr",
        "outputId": "77c79150-98dd-44df-8f30-07a8c69cb384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-99.0, 99.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определяем агентов со стратегиями\n",
        "\n",
        "# 1. Агент всегда играет \"камень\"\n",
        "def always_rock(observation, configuration):\n",
        "    return 0\n",
        "\n",
        "# 2. Агент всегда играет \"бумагу\"\n",
        "def always_paper(observation, configuration):\n",
        "    return 1\n",
        "\n",
        "# 3. Агент всегда играет \"ножницы\"\n",
        "def always_scissors(observation, configuration):\n",
        "    return 2\n",
        "\n",
        "# 4. Агент с случайным выбором\n",
        "def random_agent(observation, configuration):\n",
        "    return random.choice([0, 1, 2])\n",
        "\n",
        "# 5. Циклический агент\n",
        "def cycle_agent(observation, configuration):\n",
        "    return observation.step % 3\n",
        "\n",
        "# 6. Антициклический агент\n",
        "def anti_cycle_agent(observation, configuration):\n",
        "    return (2 - observation.step % 3)\n",
        "\n",
        "# 7. Имитация предыдущего хода противника\n",
        "def copy_opponent(observation, configuration):\n",
        "    if observation.step > 0:\n",
        "        return observation.lastOpponentAction\n",
        "    return 0\n",
        "\n",
        "# 8. Агент, играющий противоположность предыдущего хода противника\n",
        "def counter_opponent(observation, configuration):\n",
        "    if observation.step > 0:\n",
        "        return (observation.lastOpponentAction + 1) % 3\n",
        "    return 0\n",
        "\n",
        "# 9. Агент двойной камень, потом бумага\n",
        "def double_rock_then_paper(observation, configuration):\n",
        "    if observation.step % 3 < 2:\n",
        "        return 0\n",
        "    return 1\n",
        "\n",
        "# 10. Агент двойная бумага, потом ножницы\n",
        "def double_paper_then_scissors(observation, configuration):\n",
        "    if observation.step % 3 < 2:\n",
        "        return 1\n",
        "    return 2\n",
        "\n",
        "# 11. Последовательный случайный агент\n",
        "def sequential_random(observation, configuration):\n",
        "    if observation.step > 0 and random.random() < 0.7:\n",
        "        return observation.lastOpponentAction\n",
        "    return random.choice([0, 1, 2])\n",
        "\n",
        "# 12. Агент с трендом — выбирает ход, чаще всего использованный противником\n",
        "def trend_agent(observation, configuration):\n",
        "    if observation.step == 0:\n",
        "        return random.choice([0, 1, 2])\n",
        "\n",
        "    # Анализ предыдущих ходов противника\n",
        "    counts = [0, 0, 0]\n",
        "    for move in observation['opponent_history']:\n",
        "        counts[move] += 1\n",
        "    most_common = counts.index(max(counts))\n",
        "    return (most_common + 1) % 3\n",
        "\n",
        "# Формируем словарь агентов\n",
        "agents = {\n",
        "    \"Always Rock\": always_rock,\n",
        "    \"Always Paper\": always_paper,\n",
        "    \"Always Scissors\": always_scissors,\n",
        "    \"Random Agent\": random_agent,\n",
        "    \"Cycle Agent\": cycle_agent,\n",
        "    \"Anti-cycle Agent\": anti_cycle_agent,\n",
        "    \"Copy Opponent\": copy_opponent,\n",
        "    \"Counter Opponent\": counter_opponent,\n",
        "    \"Double Rock Then Paper\": double_rock_then_paper,\n",
        "    \"Double Paper Then Scissors\": double_paper_then_scissors,\n",
        "    \"Sequential Random\": sequential_random,\n",
        "    \"Trend Agent\": trend_agent\n",
        "}\n",
        "\n",
        "# Создаем функция для проведения турнира между агентами\n",
        "def run_tournament(agents):\n",
        "    # Создаем среду \"камень-ножницы-бумага\"\n",
        "    env = make(\"rps\", configuration={\"episodeSteps\": 100})\n",
        "    results = {name: 0 for name in agents}  # Словарь для хранения результатов\n",
        "\n",
        "    # Проводим турнир: каждый агент играет с каждым\n",
        "    for agent1_name, agent1 in agents.items():\n",
        "        for agent2_name, agent2 in agents.items():\n",
        "            if agent1_name == agent2_name:\n",
        "                continue  # Агент не играет сам с собой\n",
        "\n",
        "            # Настройка окружения для игры между двумя агентами\n",
        "            env.reset()\n",
        "            # Запуск игры между agent1 и agent2\n",
        "            outcome = env.run([agent1, agent2])\n",
        "            final_state = outcome[-1]  # Последний шаг\n",
        "\n",
        "            # Анализируем результат\n",
        "            reward_1 = final_state[0][\"reward\"] if final_state[0][\"reward\"] is not None else 0\n",
        "            reward_2 = final_state[1][\"reward\"] if final_state[1][\"reward\"] is not None else 0\n",
        "\n",
        "            # Обновляем счет\n",
        "            if reward_1 > reward_2:\n",
        "                results[agent1_name] += 1\n",
        "            elif reward_1 < reward_2:\n",
        "                results[agent2_name] += 1\n",
        "\n",
        "    return results\n",
        "\n",
        "# Запускаем турнир и выводим результаты\n",
        "if __name__ == \"__main__\":\n",
        "    tournament_results = run_tournament(agents)\n",
        "    # Сортируем результаты для наглядности\n",
        "    sorted_results = sorted(tournament_results.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(\"Результаты турнира:\")\n",
        "    print(f\"{'Место':<6} {'Агент':<20} {'Победы':<10}\")\n",
        "    print(\"-\" * 40)\n",
        "    for rank, (agent, score) in enumerate(sorted_results, start=1):\n",
        "        print(f\"{rank:<6} {agent:<20} {score:<10}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI2757Zww79N",
        "outputId": "66b127c9-5a1a-468a-fa39-5d75ba44297a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты турнира:\n",
            "Место  Агент                Победы    \n",
            "----------------------------------------\n",
            "1      Counter Opponent     10        \n",
            "2      Double Paper Then Scissors 10        \n",
            "3      Cycle Agent          8         \n",
            "4      Double Rock Then Paper 8         \n",
            "5      Always Paper         6         \n",
            "6      Always Scissors      6         \n",
            "7      Anti-cycle Agent     6         \n",
            "8      Always Rock          4         \n",
            "9      Copy Opponent        4         \n",
            "10     Sequential Random    4         \n",
            "11     Random Agent         2         \n",
            "12     Trend Agent          0         \n"
          ]
        }
      ]
    }
  ]
}